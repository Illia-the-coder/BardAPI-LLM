# -*- coding: utf-8 -*-
"""BardLLM

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pzd2x86Ac5W5W4f40JAmbMNtvfdiJVs-

Sure, here is an OOP style custom LLM for the Bard API:

#Bard API
In this section, we will use the Bard API to run our LLM
"""

!pip install bardapi langchain
!export BARD_TOKEN=###

import os
from bardapi import Bard
from typing import Any, List, Mapping, Optional
from langchain.callbacks.manager import CallbackManagerForLLMRun
from langchain.llms.base import LLM


class BardLLM(LLM):


    @property
    def _llm_type(self) -> str:
        return "custom"

    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
    ) -> str:
        response = Bard(token='aQjhgKn_gQ0rR3gHEXgbP-ZaPH13wzBfuEIXEeKNppVappfNr_Jd1l-Slyap6XVZld-ABw.').get_answer(prompt)['content']
        return response

    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        """Get the identifying parameters."""
        return {}

llm = BardLLM()

llm("Who is Leo DiCaprio's girlfriend?")

from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.agents import AgentType
from langchain.tools import AIPluginTool

# tool = AIPluginTool.from_plugin_url("https://www.wolframalpha.com/.well-known/ai-plugin.json")
tools = load_tools(["human"],llm=llm)
# tools += [tool]

agent_chain = initialize_agent(
    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,handle_parsing_errors=True
)

agent_chain.run("Who is Leo DiCaprio's girlfriend")